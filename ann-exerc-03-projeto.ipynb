{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Curso: Redes Neurais e Deep Learning\n",
    "\n",
    "Prof. Denilson Alves Pereira \n",
    "https://sites.google.com/ufla.br/denilsonpereira/ \n",
    "Departamento de Ciência da Computação - \n",
    "Instituto de Ciências Exatas e Tecnológicas - \n",
    "Universidade Federal de Lavras\n",
    "\n",
    "# Atividade Prática 03\n",
    "\n",
    "**Tempo estimado para execução**: 3 horas\n",
    "\n",
    "Versão: Junho, 2021"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Projeto Final\n",
    "\n",
    "O objetivo da atividade é desenvolver um projeto prático livre utilizando o conhecimento adquirido no curso. Você deve escolher um *dataset* para um problema de classificação, ler e efetuar o pré-processamento desse conjunto de dados e configurar uma rede neural para efetuar a classificação. Execute as seguintes etapas: definição, compilação e treinamento do modelo, avaliação e predição no conjunto de teste. Você deve avaliar diversas configurações para a sua rede neural, de forma a obter um resultado satisfatório. Verifique na literatura os melhores resultados obtidos com o *dataset*, se você estiver usando um *dataset* público.\n",
    "\n",
    "Para o *dataset*, escolha uma das opções abaixo:\n",
    "- um dataset que você esteja trabalhando em um projeto pessoal ou da sua empresa;\n",
    "- um dataset público.\n",
    "\n",
    "Existem diversos *datasets* públicos disponíveis na Web. A plataforma *Kaggle* (https://www.kaggle.com/) é uma das principais fontes. A *Kaggle* é formada por uma comunidade *online* de cientistas de dados e programadores em *machine learning*. Os usuários podem encontrar *datasets* e códigos em Python que os utilizam. Também podem participar de competições, fazendo parte de equipes, para resolver desafios da ciência de dados, inclusive com possibilidades de premiações em dinheiro.\n",
    "\n",
    "Este link (https://analyticsindiamag.com/10-most-popular-datasets-on-kaggle/) apresenta os 10 *datasets* mais populares na plataforma *Kaggle*.\n",
    "\n",
    "Este link (https://enoumen.com/2021/04/23/data-sciences-datasets-data-visualization-data-analytics-big-data-data-lakes/) apresenta 300 *datasets* públicos que pode ser úteis para execução da atividade prática. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importante:\n",
    "Documente cada etapa do seu código. Crie céluas de *Markdown* com textos explicativos e links para referências. Adicione comentários ao seu código."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predição de atraso em determinado voo"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O objetivo deste trabalho é fazer predições sobre o atraso de determinado voo, o dataset escolhido se encontra no link https://www.kaggle.com/datasets/jimschacko/airlines-dataset-to-predict-a-delay. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importando os pacotes \n",
    "\n",
    "import tensorflow as tf  \n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Criação do dataset e pré - processamento"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Passos :**\n",
    "\n",
    "- Lê o dataset, com a base escolhida \n",
    "- Exibe as primeiras linhas com os dados \n",
    "- Retira a váriavel Delay, e coloca em outra váriavel  que será o nosso y (ou seja o que será estimado)\n",
    "- Exibe os tipos de dados \n",
    "- Usando a função train_test_split cria-se o conjunto de testes com amostras aleatórias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   id  Flight  DayOfWeek  Time  Length  Delay\n",
      "0   1     269          3    15     205      1\n",
      "1   2    1558          3    15     222      1\n",
      "2   3    2400          3    20     165      1\n",
      "3   4    2466          3    20     195      1\n",
      "4   5     108          3    30     202      0\n",
      "id           int64\n",
      "Flight       int64\n",
      "DayOfWeek    int64\n",
      "Time         int64\n",
      "Length       int64\n",
      "Delay        int64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# lendo o csv\n",
    "\n",
    "df=pd.read_csv(\"C:/Users/iarac/Documents/CC/redes neurais/notebooks-atividades-praticas/notebooks-atividades-praticas/Airlines.csv\")\n",
    "\n",
    "#exibe data frame \n",
    "print(df.head())\n",
    "\n",
    "#separando o delay que é a variavel que irá indicar a existencia de atraso dado os dados \n",
    "\n",
    "x = df.drop([\"Delay\"], axis=1) \n",
    "y = df[\"Delay\"]\n",
    "\n",
    "#ver os tipos das variaveis\n",
    "\n",
    "print(df.dtypes)\n",
    "\n",
    "#dividir os dados em treino e teste  \n",
    "from sklearn.model_selection import train_test_split\n",
    "train_x, test_x, train_y, test_y = train_test_split(x, y , test_size=0.20, random_state=5)\n",
    "\n",
    "#remove a media e padroniza a variancia\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "train_x = scaler.fit_transform(train_x)\n",
    "test_x = scaler.fit_transform(test_x)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Criação do modelo "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Passos **\n",
    "- Cria o input e atribui os atributos da base \n",
    "- Cria uma camada com 500 neurônios com função de ativação reLU\n",
    "- Cria uma camada com 250 neurônios com função de ativação reLU\n",
    "- Cria uma camada com 10 neurônios com função de ativação reLU\n",
    "- Cria uma camada para output, com 1 neurônio que tem a ativação sigmoid\n",
    "- Usa-se keras.Model para receber o objeto com as redes\n",
    "- Exibe informações sobre o modelo criado\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_4 (InputLayer)        [(None, 5)]               0         \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 500)               3000      \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 250)               125250    \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 10)                2510      \n",
      "                                                                 \n",
      " dense_12 (Dense)            (None, 1)                 11        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 130,771\n",
      "Trainable params: 130,771\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "inputs = keras.Input(shape=(train_x.shape[1]))  \n",
    "network1 = keras.layers.Dense(units=500, activation=\"relu\")(inputs)\n",
    "network2 = keras.layers.Dense(units=250, activation=\"relu\")(network1) \n",
    "network3 = keras.layers.Dense(units=10, activation=\"relu\")(network2)\n",
    "outputs = keras.layers.Dense(units=1, activation=\"sigmoid\")(network3)\n",
    "#variavel model recebe a criação do modelo \n",
    "model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compilação do Modelo "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O método compile configura o processo de treinamento da rede neural.\n",
    "- Otimizador: Adam\n",
    "- Função de Perda: Binary Crossentropy \n",
    "- Metrics : Accuracy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\",  metrics='accuracy' ) "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Treinamento do modelo \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O método fit é usado para fazer o treinamento da rede neural , ele recebe os dados de treinamento e ajusta os pesos. O tamanho do lote escolhido é 20 e \n",
    "o número de vezes que a rede vai ser processada é 10. (Passando pelo conjunto de dados)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "21576/21576 [==============================] - 192s 9ms/step - loss: 0.6549 - accuracy: 0.6097\n",
      "Epoch 2/10\n",
      "21576/21576 [==============================] - 221s 10ms/step - loss: 0.6488 - accuracy: 0.6177\n",
      "Epoch 3/10\n",
      "21576/21576 [==============================] - 205s 10ms/step - loss: 0.6466 - accuracy: 0.6222\n",
      "Epoch 4/10\n",
      "21576/21576 [==============================] - 200s 9ms/step - loss: 0.6454 - accuracy: 0.6238\n",
      "Epoch 5/10\n",
      "21576/21576 [==============================] - 184s 9ms/step - loss: 0.6450 - accuracy: 0.6240\n",
      "Epoch 6/10\n",
      "21576/21576 [==============================] - 178s 8ms/step - loss: 0.6442 - accuracy: 0.6255\n",
      "Epoch 7/10\n",
      "21576/21576 [==============================] - 182s 8ms/step - loss: 0.6440 - accuracy: 0.6258\n",
      "Epoch 8/10\n",
      "21576/21576 [==============================] - 210s 10ms/step - loss: 0.6436 - accuracy: 0.6263\n",
      "Epoch 9/10\n",
      "21576/21576 [==============================] - 204s 9ms/step - loss: 0.6432 - accuracy: 0.6268\n",
      "Epoch 10/10\n",
      "21576/21576 [==============================] - 189s 9ms/step - loss: 0.6429 - accuracy: 0.6265\n",
      "<keras.callbacks.History object at 0x000001DC610AB130>\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_x, train_y, batch_size=20, epochs=10) \n",
    "print(history)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Avaliação do Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3372/3372 [==============================] - 13s 4ms/step - loss: 0.6446 - accuracy: 0.6244\n",
      "0.6445845365524292\n",
      "0.62441486120224\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(test_x, test_y) \n",
    "print(loss)\n",
    "print(accuracy)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Temos que a função de perda é 0.6445 e a acurácia é 0.62441\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predição "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3372/3372 [==============================] - 14s 4ms/step\n",
      "Predictions:  [0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1]\n",
      "\n",
      "Correct:      [0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1]\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(test_x)\n",
    "print(\"Predictions: \", [round(x[0]) for x in predictions][:200])\n",
    "print(\"\\nCorrect:     \", [round(x) for x in test_y] [:200])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como foram muitas predições, eu imprimi as vinte primeiras. Através delas é possivel dizer qual avião sofrerá um atraso de acordo com os dados referentes\n",
    "ao id, Flight, DayOfWeek, Time e Length. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ann",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "92386a23fbe9b4bce55b77b737b6f43a996f40dbfcd343d1a62c87d60afc817f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
